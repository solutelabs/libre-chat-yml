version: 1.2.8
 
cache: true
 
interface:
  # MCP Servers UI configuration
  mcpServers:
  internal-tools:
    command: npx
    args: ["-y", "internal-mcp-server"]
    chatMenu: true  # Only available in agent builder
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  customWelcome: "Hey {{user.name}}! Welcome to SoluteLabs GreatWrk Enterprise Version"
  runCode: true
  webSearch: true
  fileSearch: true
  fileCitations: true
  
registration:
  socialLogins: ["google"]
  allowedDomains: 
    - "solutelabs.com"

memory:
  disabled: false
  validKeys: ["user_preferences", "conversation_context", "personal_info"]
  tokenLimit: 2000
  personalize: true
  messageWindowSize: 5
  agent:
    provider: "openAI"
    model: "gpt-5"
    instructions: "You are a helpful assistant that remembers user preferences and context."
    model_parameters:
      temperature: 0.7
      max_tokens: 1000
 
endpoints:
  agents:
    recursionLimit: 50
    maxRecursionLimit: 100
    disableBuilder: false
    # (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
    # capabilities: ["execute_code", "file_search", "actions", "tools", "artifacts", "ocr", "chain", "web_search"]
    # (optional) File citation configuration for file_search capability
    maxCitations: 30          # Maximum total citations in responses (1-50)
    maxCitationsPerFile: 7    # Maximum citations from each file (1-10)
    minRelevanceScore: 0.45   # Minimum relevance score threshold (0.0-1.0)
  
  custom:
 
    #cohere
    - name: "cohere"
        apiKey: "${COHERE_API_KEY}"
        baseURL: "https://api.cohere.ai/v1"
        models:
          default: ["command-r","command-r-plus","command-light","command-light-nightly","command","command-nightly"]
          fetch: true
        modelDisplayLabel: "cohere"
        titleModel: "command"
        dropParams: ["stop", "user", "frequency_penalty", "presence_penalty", "temperature", "top_p"]

        # Example using Mistral AI API
    - name: "Mistral"
        apiKey: "${MISTRAL_API_KEY}"
        baseURL: "https://api.mistral.ai/v1"
        models: 
          default: ["mistral-tiny", "mistral-small", "mistral-medium", "mistral-large-latest"]
          titleConvo: true
        titleModel: "mistral-tiny" 
        modelDisplayLabel: "Mistral"
        # addParams:
        #   safe_prompt: true # Mistral specific value for moderating messages
        # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:
        dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]      

